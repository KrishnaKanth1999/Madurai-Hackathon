{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np \nimport json\nimport pandas as pd\nimport math, nltk, warnings\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.neighbors import KDTree\nfrom collections import Counter\nwarnings.filterwarnings(\"ignore\")",
      "execution_count": 121,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "#loading movies data\ndef load_movies(path):\n    df = pd.read_csv(path)\n    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.date())\n    json_columns = ['genres', 'keywords', 'production_countries',\n                    'production_companies', 'spoken_languages']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n#loading crew data\ndef load_crew(path):\n    df = pd.read_csv(path)\n    json_columns = ['cast', 'crew']\n    for column in json_columns:\n        df[column] = df[column].apply(json.loads)\n    return df\n#renaming\ncolumn_rename = {'budget': 'budget','genres': 'genres','revenue': 'gross','title': 'movie_title','runtime': 'duration','original_language': 'language','keywords': 'plot_keywords','vote_count': 'num_voted_users'}\n\ndef miss_value(container, index_values):\n    result = container\n    try:\n        for idx in index_values:\n            result = result[idx]\n        return result\n    except IndexError or KeyError:\n        return pd.np.nan\n#getting directors    \ndef get_director(crew_data):\n    directors = [x['name'] for x in crew_data if x['job'] == 'Director']\n    return miss_value(directors, [0])    \n#converting to string\ndef join_names(keywords):\n    return '|'.join([x['name'] for x in keywords])\n#combining movies and crew\ndef join_two(movies, credits):\n    movies_data = movies.copy()\n    movies_data.rename(columns=column_rename, inplace=True)\n    movies_data['title_year'] = pd.to_datetime(movies_data['release_date']).apply(lambda x: x.year)\n    movies_data['country'] = movies_data['production_countries'].apply(lambda x: miss_value(x, [0, 'name']))\n    movies_data['language'] = movies_data['spoken_languages'].apply(lambda x: miss_value(x, [0, 'name']))\n    movies_data['director_name'] = credits['crew'].apply(get_director)\n    movies_data['actor_1_name'] = credits['cast'].apply(lambda x: miss_value(x, [1, 'name']))\n    movies_data['actor_2_name'] = credits['cast'].apply(lambda x: miss_value(x, [2, 'name']))\n    movies_data['actor_3_name'] = credits['cast'].apply(lambda x:miss_value(x, [3, 'name']))\n    movies_data['genres'] = movies_data['genres'].apply(join_names)\n    movies_data['plot_keywords'] = movies_data['plot_keywords'].apply(join_names)\n    return movies_data    \nprint('1')",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": "1\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "26ea86482b6405557c2d99ca1a59983cf7ef226f"
      },
      "cell_type": "code",
      "source": "credits = load_crew(\"../input/tmdb_5000_credits.csv\")\nmovies = load_movies(\"../input/tmdb_5000_movies.csv\")\ndata_set = join_two(movies, credits)\n",
      "execution_count": 124,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "038bdce5447a3a7b473fba0d520820a5d50a8bb8"
      },
      "cell_type": "code",
      "source": "#dropping unwanted columns\ndata_set=data_set.drop(['homepage','tagline','status','spoken_languages','release_date','production_companies','production_countries','original_title','overview','vote_average'],axis=1)",
      "execution_count": 125,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "3d5150608d6614707db6f078518f1d6b5cf5a784"
      },
      "cell_type": "code",
      "source": "#getting actors names\nfirst_actors = set(data_set.actor_1_name.unique())\nsecond_actors = set(data_set.actor_2_name.unique())\nthird_actors = set(data_set.actor_3_name.unique())\nunique_genre_labels = set()\nfor genre_flags in data_set.genres.str.split('|').values:\n    unique_genre_labels = unique_genre_labels.union(set(genre_flags))\nfor label in unique_genre_labels:\n    data_set['Genre='+label] = data_set.genres.str.contains(label).astype(int)\ndata_set = data_set.drop('genres', axis=1)\n\n#Dropping_duplicates\nif len(data_set.drop_duplicates(subset=['movie_title',\n                                  'title_year'])) < len(data_set):\n    print('Duplicate Titles Exist')\n    \n    duplicates = data_set[data_set.movie_title.map(data_set.movie_title.value_counts() > 1)]\n    duplicates.sort('movie_title')[['movie_title', 'title_year']]\n   \n    data_set = data_set.drop_duplicates(subset=['movie_title', 'title_year'])\n\n    duplicates = data_set[data_set.movie_title.map(data_set.movie_title.value_counts() > 1)]\n    duplicates.sort('movie_title')[['movie_title', 'title_year']]\n   \n    data_set = data_set.drop_duplicates(subset=['movie_title', 'title_year'])\n    \ncounts = data_set.language.value_counts()\ndata_set.language = data_set.language.map(counts)\n\ncount = data_set.country.value_counts()\ndata_set.country = data_set.country.map(count)\n\nprint('1')",
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": "1\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "102271e35331797ac5d795ffb9a0fda194772fc5"
      },
      "cell_type": "code",
      "source": "#getting unique keywords and handling categorical values\nunique_words = set()\nfor wordlist in data_set.plot_keywords.str.split('|').values:\n    if wordlist is not np.nan:\n        unique_words = unique_words.union(set(wordlist))\nplot_wordbag = list(unique_words)\nfor word in plot_wordbag:\n    data_set['plot_has_' + word.replace(' ', '-')] = data_set.plot_keywords.str.contains(word).astype(float)\ndata_set = data_set.drop('plot_keywords', axis=1)\n\ndata_set.director_name = data_set.director_name.map(data_set.director_name.value_counts())\n\ncounts = pd.concat([data_set.actor_1_name, data_set.actor_2_name, data_set.actor_3_name]).value_counts()\n\ndata_set.actor_1_name = data_set.actor_1_name.map(counts)\ndata_set.actor_2_name = data_set.actor_2_name.map(counts)\ndata_set.actor_3_name = data_set.actor_3_name.map(counts)\ndata_set.select_dtypes(include=['O']).columns\n\nprint('2')",
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": "2\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "0dd16df793385bc4fbcdb79b92dba47b5f0b514a"
      },
      "cell_type": "code",
      "source": "#dropping rows which has null values\n\ndata_set=data_set.dropna()\n\n#storing movie names in an array\n\ntitles=data_set.movie_title\ndef recoms(names):\n    movies = []\n    for name in names:\n        found = [i for i in titles if name.lower() in i.lower()]\n        \n        if len(found) > 0:\n            movies.append(found[0])\n    return  movies\ndata = data_set.drop('movie_title', axis=1)\ndata = MinMaxScaler().fit_transform(data)\n\n#forming a KD Tree with our data\n\ntree = KDTree(data, leaf_size=1)\n\n#recommending movies based on users movies list\n\ndef final_recommendations(movies, tree, titles, data):\n    titles = list(titles)\n    length, recommendations = len(movies) + 1,[]\n    \n    for i, movie in enumerate(movies):\n        weight = length - i\n        dist, index = tree.query([data[titles.index(movie)]], k=4)\n        for d, m in zip(dist[0], index[0]):\n            recommendations.append((d*weight, titles[m]))\n    recommendations.sort()\n    rec = [i[1].strip() for i in recommendations if i[1] not in movies]\n    \n    rec = [i[1] for i in sorted([(v, k) for k, v in Counter(rec).items()],\n                                reverse=True)]\n    return rec\n\nprint('step 4')",
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": "step 4\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7c2382eefe60e6de0febd0166695e9d839aa84d9"
      },
      "cell_type": "code",
      "source": "#Finally,you can get some great movies!\n\nuser_movies = []\nprint('Type the number of movies u want to enter')\nnumber=input()\nprint('Type',number,'movies')\nfor i in range(int(number)):\n    user_input = input()\n    user_movies += [user_input]\n\nmovies = recoms(user_movies)\nresult = final_recommendations(movies, tree, titles, data)\nprint('Recommended Movies are:')\nft = '{}. {}'\nfor i, item in enumerate(result[:len(result)]):\n    print(ft.format(i + 1, item))\n",
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Type the number of movies u want to enter\n5\nType 5 movies\n3:10 to Yuma\nTombstone\nUnforgiven\nThe Assassination of Jesse James by the Coward Robert Ford\nOpen Range\nRecommended Movies are:\n1. Western Religion\n2. Shanghai Calling\n3. Duel in the Sun\n4. Slow Burn\n5. S.W.A.T.\n6. Red Riding: In the Year of Our Lord 1974\n7. Nowhere to Run\n8. Money Talks\n9. Jane Got a Gun\n10. Forsaken\n11. F.I.S.T.\n12. Broken Horses\n",
          "name": "stdout"
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}